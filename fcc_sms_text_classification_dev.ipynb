{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8RZOuS9LWQvv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:45:30.440989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 19:45:30.652418: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "# try:\n",
    "#   # %tensorflow_version only exists in Colab.\n",
    "#   !pip install tf-nightly\n",
    "# except Exception:\n",
    "#   pass\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "# !pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lMHwYXHXCar3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-07 20:02:23--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
      "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 172.67.70.149, 104.26.3.33, ...\n",
      "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 358233 (350K) [text/tab-separated-values]\n",
      "Saving to: ‘train-data.tsv’\n",
      "\n",
      "train-data.tsv      100%[===================>] 349.84K  1.45MB/s    in 0.2s    \n",
      "\n",
      "2023-03-07 20:02:24 (1.45 MB/s) - ‘train-data.tsv’ saved [358233/358233]\n",
      "\n",
      "--2023-03-07 20:02:24--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
      "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.2.33, 104.26.3.33, ...\n",
      "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118774 (116K) [text/tab-separated-values]\n",
      "Saving to: ‘valid-data.tsv’\n",
      "\n",
      "valid-data.tsv      100%[===================>] 115.99K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-03-07 20:02:24 (1.09 MB/s) - ‘valid-data.tsv’ saved [118774/118774]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get data files\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
    "\n",
    "train_file_path = \"train-data.tsv\"\n",
    "test_file_path = \"valid-data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g_h508FEClxO"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_table('train-data.tsv', names=['ham_or_spam', 'sms'])\n",
    "df_val = pd.read_table('valid-data.tsv', names=['ham_or_spam', 'sms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4179, 2), (1392, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3619\n",
       "spam     560\n",
       "Name: ham_or_spam, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the class distribution\n",
    "df_train['ham_or_spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     1205\n",
       "spam     187\n",
       "Name: ham_or_spam, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the class distribution in the validation set\n",
    "df_val['ham_or_spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham_or_spam</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>ham</td>\n",
       "      <td>anyway seriously hit me up when you're back be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>spam</td>\n",
       "      <td>we tried to contact you re our offer of new vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>ham</td>\n",
       "      <td>in that case i guess i'll see you at campus lodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>ham</td>\n",
       "      <td>take some small dose tablet for fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>ham</td>\n",
       "      <td>and how you will do that, princess? :)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ham_or_spam                                                sms\n",
       "1408         ham  anyway seriously hit me up when you're back be...\n",
       "3072        spam  we tried to contact you re our offer of new vi...\n",
       "3607         ham  in that case i guess i'll see you at campus lodge\n",
       "2136         ham              take some small dose tablet for fever\n",
       "2421         ham             and how you will do that, princess? :)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view 5 random samples from the training set\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a label column for the model\n",
    "df_train['label'] = df_train['ham_or_spam'].map({'ham': 0, 'spam': 1})\n",
    "df_val['label'] = df_val['ham_or_spam'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3619, 560)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up class weights to account for the small number of 'spam' samples\n",
    "neg = (df_train['label'] == 0).sum()\n",
    "pos = (df_train['label'] == 1).sum()\n",
    "neg, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5773694390715667, 1: 3.7312499999999997}\n"
     ]
    }
   ],
   "source": [
    "counts = df_train['label'].value_counts()\n",
    "neg = counts[0]\n",
    "pos = counts[1]\n",
    "\n",
    "weight_for_0 = (1 / neg) * (len(df_train) / 2.0)\n",
    "weight_for_1 = (1 / pos) * (len(df_train) / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham_or_spam</th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>you can never do nothing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>now u sound like manky scouse boy steve,like! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>mum say we wan to go then go... then she can s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ham_or_spam                                                sms  label\n",
       "0         ham  ahhhh...just woken up!had a bad dream about u ...      0\n",
       "1         ham                           you can never do nothing      0\n",
       "2         ham  now u sound like manky scouse boy steve,like! ...      0\n",
       "3         ham  mum say we wan to go then go... then she can s...      0\n",
       "4         ham  never y lei... i v lazy... got wat? dat day ü ...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train and validation data in numpy arrays\n",
    "train_texts = df_train['sms'].to_numpy()\n",
    "train_labels = df_train['label'].to_numpy()\n",
    "val_texts = df_val['sms'].to_numpy()\n",
    "val_labels = df_val['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham_or_spam</th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>ham</td>\n",
       "      <td>i was about to do it when i texted. i finished a long time ago and showered and er'ything!</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>ham</td>\n",
       "      <td>haha awesome, i might need to take you up on that, what you doin tonight?</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>ham</td>\n",
       "      <td>i'm leaving my house now.</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>ham</td>\n",
       "      <td>how come guoyang go n tell her? then u told her?</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>ham</td>\n",
       "      <td>hello which the site to download songs its urgent pls</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>ham</td>\n",
       "      <td>o we cant see if we can join denis and mina? or does denis want alone time</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>ham</td>\n",
       "      <td>hi its kate how is your evening? i hope i can see you tomorrow for a bit but i have to bloody babyjontet! txt back if u can. :) xxx</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>ham</td>\n",
       "      <td>u wan 2 haf lunch i'm in da canteen now.</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>ham</td>\n",
       "      <td>ya, told..she was asking wats matter?</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>ham</td>\n",
       "      <td>i not free today i haf 2 pick my parents up tonite...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ham_or_spam  \\\n",
       "1743         ham   \n",
       "620          ham   \n",
       "1252         ham   \n",
       "3165         ham   \n",
       "2191         ham   \n",
       "651          ham   \n",
       "2997         ham   \n",
       "2104         ham   \n",
       "1898         ham   \n",
       "2878         ham   \n",
       "\n",
       "                                                                                                                                      sms  \\\n",
       "1743                                           i was about to do it when i texted. i finished a long time ago and showered and er'ything!   \n",
       "620                                                             haha awesome, i might need to take you up on that, what you doin tonight?   \n",
       "1252                                                                                                            i'm leaving my house now.   \n",
       "3165                                                                                     how come guoyang go n tell her? then u told her?   \n",
       "2191                                                                                hello which the site to download songs its urgent pls   \n",
       "651                                                            o we cant see if we can join denis and mina? or does denis want alone time   \n",
       "2997  hi its kate how is your evening? i hope i can see you tomorrow for a bit but i have to bloody babyjontet! txt back if u can. :) xxx   \n",
       "2104                                                                                             u wan 2 haf lunch i'm in da canteen now.   \n",
       "1898                                                                                                ya, told..she was asking wats matter?   \n",
       "2878                                                                                i not free today i haf 2 pick my parents up tonite...   \n",
       "\n",
       "      label  tokens  \n",
       "1743      0      19  \n",
       "620       0      15  \n",
       "1252      0       5  \n",
       "3165      0      11  \n",
       "2191      0      10  \n",
       "651       0      17  \n",
       "2997      0      30  \n",
       "2104      0      10  \n",
       "1898      0       6  \n",
       "2878      0      12  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "# inspect a sample of the training data\n",
    "df_sample = df_train.sample(10)\n",
    "# add a column with the number of words in each text\n",
    "df_sample['tokens'] = df_sample['sms'].apply(lambda x: len(x.split()))\n",
    "df_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up text processing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the max number of tokens in train_texts\n",
    "max_length = max([len(i.split()) for i in train_texts])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the median number of tokens in train_texts\n",
    "median_length = np.median([len(i.split()) for i in train_texts])\n",
    "median_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.604450825556354"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the average number of tokens in train_texts\n",
    "avg_length = np.mean([len(i.split()) for i in train_texts])\n",
    "avg_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# max number of words to use in our vocab\n",
    "max_vocab_length = 10000\n",
    "# max tokens in each text\n",
    "output_sequence_length = 30\n",
    "\n",
    "# create a text vectorizer layer\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode='int',\n",
    "                                    output_sequence_length=output_sequence_length)\n",
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=int64, numpy=array([[ 3, 69,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out the text vectorizer with a sample text\n",
    "sample_text = 'I love machine learning'\n",
    "text_vectorizer([sample_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer\n",
    "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length,\n",
    "                                      output_dim=128, # output shape,\n",
    "                                      input_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi dear we saw dear. we both are happy. where you my battery is low\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16, 128), dtype=float32, numpy=\n",
       "array([[[-0.02435087,  0.03975994, -0.00540585, ..., -0.0358328 ,\n",
       "         -0.0108956 ,  0.03641697],\n",
       "        [ 0.01703156, -0.0277077 , -0.02375525, ..., -0.04986947,\n",
       "          0.02598711,  0.04096658],\n",
       "        [ 0.0400219 ,  0.04994031,  0.04106606, ...,  0.02158229,\n",
       "         -0.03520878,  0.01922883],\n",
       "        ...,\n",
       "        [ 0.03981615, -0.02227314, -0.04821194, ...,  0.04713095,\n",
       "          0.02334302, -0.03417813],\n",
       "        [ 0.02281949, -0.01116902, -0.02656424, ...,  0.0171528 ,\n",
       "          0.02070067, -0.03872194],\n",
       "        [ 0.00640814, -0.04977547, -0.0315617 , ..., -0.02413393,\n",
       "          0.00196383,  0.00353675]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "import random\n",
    "random_sentence = random.choice(train_texts)\n",
    "print(random_sentence)\n",
    "\n",
    "embedding(text_vectorizer([random_sentence]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - simple Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of those numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the embedding down to one vector\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x) # create an output layer\n",
    "model_1 = tf.keras.Model(inputs, outputs, name='model_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 30)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       multiple                  1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 128)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.9584 - precision_7: 0.8755 - recall_7: 0.8036 - val_loss: 0.2057 - val_accuracy: 0.9806 - val_precision_7: 0.9819 - val_recall_7: 0.8717\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.1646 - accuracy: 0.9933 - precision_7: 1.0000 - recall_7: 0.9500 - val_loss: 0.1280 - val_accuracy: 0.9813 - val_precision_7: 0.9708 - val_recall_7: 0.8877\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0961 - accuracy: 0.9955 - precision_7: 0.9963 - recall_7: 0.9696 - val_loss: 0.1007 - val_accuracy: 0.9835 - val_precision_7: 0.9659 - val_recall_7: 0.9091\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0669 - accuracy: 0.9976 - precision_7: 0.9964 - recall_7: 0.9857 - val_loss: 0.0841 - val_accuracy: 0.9864 - val_precision_7: 0.9667 - val_recall_7: 0.9305\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0507 - accuracy: 0.9978 - precision_7: 0.9964 - recall_7: 0.9875 - val_loss: 0.0759 - val_accuracy: 0.9871 - val_precision_7: 0.9669 - val_recall_7: 0.9358\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0401 - accuracy: 0.9986 - precision_7: 1.0000 - recall_7: 0.9893 - val_loss: 0.0676 - val_accuracy: 0.9856 - val_precision_7: 0.9665 - val_recall_7: 0.9251\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0330 - accuracy: 0.9988 - precision_7: 1.0000 - recall_7: 0.9911 - val_loss: 0.0663 - val_accuracy: 0.9864 - val_precision_7: 0.9615 - val_recall_7: 0.9358\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0275 - accuracy: 0.9988 - precision_7: 0.9982 - recall_7: 0.9929 - val_loss: 0.0613 - val_accuracy: 0.9856 - val_precision_7: 0.9613 - val_recall_7: 0.9305\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9988 - precision_7: 0.9982 - recall_7: 0.9929 - val_loss: 0.0590 - val_accuracy: 0.9856 - val_precision_7: 0.9613 - val_recall_7: 0.9305\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9990 - precision_7: 0.9982 - recall_7: 0.9946 - val_loss: 0.0564 - val_accuracy: 0.9856 - val_precision_7: 0.9613 - val_recall_7: 0.9305\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9990 - precision_7: 0.9982 - recall_7: 0.9946 - val_loss: 0.0530 - val_accuracy: 0.9871 - val_precision_7: 0.9721 - val_recall_7: 0.9305\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9990 - precision_7: 0.9982 - recall_7: 0.9946 - val_loss: 0.0509 - val_accuracy: 0.9871 - val_precision_7: 0.9721 - val_recall_7: 0.9305\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0139 - accuracy: 0.9993 - precision_7: 0.9982 - recall_7: 0.9964 - val_loss: 0.0516 - val_accuracy: 0.9856 - val_precision_7: 0.9613 - val_recall_7: 0.9305\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0124 - accuracy: 0.9993 - precision_7: 0.9982 - recall_7: 0.9964 - val_loss: 0.0492 - val_accuracy: 0.9864 - val_precision_7: 0.9667 - val_recall_7: 0.9305\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.9993 - precision_7: 0.9982 - recall_7: 0.9964 - val_loss: 0.0494 - val_accuracy: 0.9849 - val_precision_7: 0.9560 - val_recall_7: 0.9305\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0101 - accuracy: 0.9993 - precision_7: 0.9982 - recall_7: 0.9964 - val_loss: 0.0487 - val_accuracy: 0.9864 - val_precision_7: 0.9615 - val_recall_7: 0.9358\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0091 - accuracy: 0.9993 - precision_7: 0.9982 - recall_7: 0.9964 - val_loss: 0.0470 - val_accuracy: 0.9864 - val_precision_7: 0.9667 - val_recall_7: 0.9305\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9993 - precision_7: 0.9982 - recall_7: 0.9964 - val_loss: 0.0474 - val_accuracy: 0.9864 - val_precision_7: 0.9615 - val_recall_7: 0.9358\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9995 - precision_7: 0.9982 - recall_7: 0.9982 - val_loss: 0.0463 - val_accuracy: 0.9871 - val_precision_7: 0.9669 - val_recall_7: 0.9358\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.9995 - precision_7: 0.9982 - recall_7: 0.9982 - val_loss: 0.0462 - val_accuracy: 0.9864 - val_precision_7: 0.9615 - val_recall_7: 0.9358\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_1 = model_1.fit(train_texts,\n",
    "            train_labels,\n",
    "            epochs=10,\n",
    "            validation_data=(val_texts, val_labels),\n",
    "            class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9878 - precision_4: 0.9620 - recall_4: 0.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06076987460255623,\n",
       " 0.9877873659133911,\n",
       " 0.9619565010070801,\n",
       " 0.9465240836143494]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "model_1.evaluate(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "You passed the challenge. Great job!\n"
     ]
    }
   ],
   "source": [
    "test_predictions(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name='model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "131/131 [==============================] - 9s 15ms/step - loss: 0.0701 - accuracy: 0.9868 - precision_5: 0.9287 - recall_5: 0.9768 - val_loss: 0.1218 - val_accuracy: 0.9784 - val_precision_5: 0.9026 - val_recall_5: 0.9412\n",
      "Epoch 2/10\n",
      "131/131 [==============================] - 2s 13ms/step - loss: 0.0068 - accuracy: 0.9988 - precision_5: 0.9912 - recall_5: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9842 - val_precision_5: 0.9412 - val_recall_5: 0.9412\n",
      "Epoch 3/10\n",
      "131/131 [==============================] - 2s 13ms/step - loss: 0.0045 - accuracy: 0.9990 - precision_5: 0.9929 - recall_5: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9842 - val_precision_5: 0.9459 - val_recall_5: 0.9358\n",
      "Epoch 4/10\n",
      "131/131 [==============================] - 2s 13ms/step - loss: 0.0035 - accuracy: 0.9990 - precision_5: 0.9929 - recall_5: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9856 - val_precision_5: 0.9665 - val_recall_5: 0.9251\n",
      "Epoch 5/10\n",
      "131/131 [==============================] - 2s 12ms/step - loss: 0.0102 - accuracy: 0.9978 - precision_5: 0.9876 - recall_5: 0.9964 - val_loss: 0.0956 - val_accuracy: 0.9849 - val_precision_5: 0.9560 - val_recall_5: 0.9305\n",
      "Epoch 6/10\n",
      "131/131 [==============================] - 2s 13ms/step - loss: 0.0037 - accuracy: 0.9993 - precision_5: 0.9947 - recall_5: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9856 - val_precision_5: 0.9563 - val_recall_5: 0.9358\n",
      "Epoch 7/10\n",
      "131/131 [==============================] - 2s 15ms/step - loss: 0.0036 - accuracy: 0.9993 - precision_5: 0.9947 - recall_5: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9856 - val_precision_5: 0.9563 - val_recall_5: 0.9358\n",
      "Epoch 8/10\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.0035 - accuracy: 0.9993 - precision_5: 0.9947 - recall_5: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9856 - val_precision_5: 0.9563 - val_recall_5: 0.9358\n",
      "Epoch 9/10\n",
      "131/131 [==============================] - 2s 17ms/step - loss: 0.0034 - accuracy: 0.9993 - precision_5: 0.9947 - recall_5: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9856 - val_precision_5: 0.9563 - val_recall_5: 0.9358\n",
      "Epoch 10/10\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.0033 - accuracy: 0.9993 - precision_5: 0.9947 - recall_5: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9856 - val_precision_5: 0.9563 - val_recall_5: 0.9358\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history_2 = model_2.fit(train_texts,\n",
    "                        train_labels,\n",
    "                        epochs=10,\n",
    "                        validation_data=(val_texts, val_labels),\n",
    "                        class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9856 - precision_5: 0.9563 - recall_5: 0.9358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10771406441926956,\n",
       " 0.9856321811676025,\n",
       " 0.9562841653823853,\n",
       " 0.9358288645744324]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "model_2.evaluate(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "You passed the challenge. Great job!\n"
     ]
    }
   ],
   "source": [
    "test_predictions(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Multi-layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "inputs = layers.Input(shape=(1,), dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name='model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 30)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       multiple                  1280000   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 30, 64)            49408     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,366,657\n",
      "Trainable params: 1,366,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "131/131 [==============================] - 5s 23ms/step - loss: 0.0561 - accuracy: 0.9916 - precision_6: 0.9472 - recall_6: 0.9929 - val_loss: 0.1281 - val_accuracy: 0.9784 - val_precision_6: 0.9067 - val_recall_6: 0.9358\n",
      "Epoch 2/5\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.0123 - accuracy: 0.9969 - precision_6: 0.9790 - recall_6: 0.9982 - val_loss: 0.0650 - val_accuracy: 0.9864 - val_precision_6: 0.9565 - val_recall_6: 0.9412\n",
      "Epoch 3/5\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.0088 - accuracy: 0.9993 - precision_6: 0.9964 - recall_6: 0.9982 - val_loss: 0.1203 - val_accuracy: 0.9813 - val_precision_6: 0.9215 - val_recall_6: 0.9412\n",
      "Epoch 4/5\n",
      "131/131 [==============================] - 3s 21ms/step - loss: 0.0038 - accuracy: 0.9993 - precision_6: 0.9947 - recall_6: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9842 - val_precision_6: 0.9558 - val_recall_6: 0.9251\n",
      "Epoch 5/5\n",
      "131/131 [==============================] - 4s 28ms/step - loss: 0.0037 - accuracy: 0.9990 - precision_6: 0.9929 - recall_6: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9799 - val_precision_6: 0.8995 - val_recall_6: 0.9572\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history_3 = model_3.fit(train_texts,\n",
    "                        train_labels,\n",
    "                        epochs=5,\n",
    "                        validation_data=(val_texts, val_labels),\n",
    "                        class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9799 - precision_6: 0.8995 - recall_6: 0.9572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10481208562850952,\n",
       " 0.9798850417137146,\n",
       " 0.8994975090026855,\n",
       " 0.9572192430496216]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "You passed the challenge. Great job!\n"
     ]
    }
   ],
   "source": [
    "test_predictions(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "J9tD9yACG6M9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "[0, 'ham']\n"
     ]
    }
   ],
   "source": [
    "# function to predict messages based on model\n",
    "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
    "def predict_message(pred_text, model=model_1):\n",
    "  prediction = round(model.predict([pred_text])[0][0])\n",
    "\n",
    "  if prediction == 0:\n",
    "    return [prediction, 'ham']\n",
    "  else:\n",
    "    return [prediction, 'spam']\n",
    "\n",
    "pred_text = \"how are you doing today?\"\n",
    "\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Dxotov85SjsC"
   },
   "outputs": [],
   "source": [
    "# Run this cell to test your function and model. Do not modify contents.\n",
    "def test_predictions(model):\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won £1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg, model)\n",
    "    # print(f'{prediction[1]}: {msg}')\n",
    "    if prediction[1] != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"You passed the challenge. Great job!\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying.\")\n",
    "\n",
    "# test_predictions()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fcc_sms_text_classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "data-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
